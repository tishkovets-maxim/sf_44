{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + проверено (взято новое)\n",
    "\n",
    "# 1. Импорты и загрузка файлов\n",
    "# 1.0. Импорты\n",
    "import pandas as pd\n",
    "import pathlib as pth\n",
    "from datetime import datetime\n",
    "\n",
    "data_dir = pth.Path(r'c:\\DATA\\DOC\\_Personal\\учеба\\VS Code\\44. Проект\\data')\n",
    "events_file = data_dir/r'7_4_Events.csv'\n",
    "purchase_file = data_dir/r'7_4_Purchase.csv'\n",
    "\n",
    "levels_arranged = ('easy', 'medium', 'hard')\n",
    "events_arranged = ('registration', 'tutorial_start', 'tutorial_finish', 'level_choice', 'pack_choice', 'purchase')\n",
    "\n",
    "# 1.1. Читаем основной лог\n",
    "events_df = pd.read_csv ( events_file,\n",
    "      dtype = {'selected_level': 'category',\n",
    "              'id': 'Int64', 'tutorial_id': 'Int64', 'user_id': 'Int64'}\n",
    "    )\n",
    "events_df['start_time'] = pd.to_datetime \\\n",
    "        (   events_df['start_time'],\n",
    "            format='%Y-%m-%dT%H:%M:%S', errors='coerce'\n",
    "        )\n",
    "\n",
    "# 1.2. Читаем файл про покупки\n",
    "purchase_df = pd.read_csv ( purchase_file,\n",
    "     dtype =  {'id': 'Int64', 'user_id': 'Int64',\n",
    "               'amount': 'float64'}\n",
    "    )\n",
    "purchase_df['event_datetime'] = pd.to_datetime \\\n",
    "        (   purchase_df['event_datetime'],\n",
    "            format='%Y-%m-%dT%H:%M:%S', errors='coerce'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + проверено\n",
    "\n",
    "# Функции\n",
    "# Краткое описание датафрейма в удобной мне форме\n",
    "def df_describe(df):\n",
    "    return pd.DataFrame\\\n",
    "    ({  'dtype':        df.dtypes\n",
    "        , 'distinct':   df.nunique()\n",
    "        , 'empty':      df.isna().sum()\n",
    "    })\n",
    "\n",
    "# \"Сплющивание\" многоуровневых столбцов\n",
    "def df_flatten_headers (df):\n",
    "    df.columns = \\\n",
    "        [':'.join([x for x in col]) \n",
    "        for col in df.columns.to_flat_index()\n",
    "        ]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Характеристика данных.\n",
    "# Непосредственно ход первичного анализа данных пропущу. \n",
    "# Ниже представлены его итоги\n",
    "\n",
    "print ('events_df')\n",
    "display (df_describe (events_df))\n",
    "print ('purchase_df')\n",
    "display (df_describe (purchase_df))\n",
    "print (\"purchase_df['amount']\")\n",
    "display (purchase_df['amount'].describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X. Выводы по первичному анализу данных\n",
    "#### events_df\n",
    "1. Пропуски в столбцах selected_level, tutorial_id, что логично, т.к. не все пользователи выбирали уровень и проходили обучение\n",
    "2. Пропуск в столбце start_time: в исходных данных были некорректные (2017.02.29), либо запорченные (20162015-09-18) даты. Решено было пропустить такие даты, не пытаясь интерпретировать\n",
    "3. Столбец selected_level приводится к категориальному формату сразу.\n",
    "4. Столбец event_type будет приведен к категориальному формату позже - после соединения датафреймов (будет добавлена категория \"purchase\")\n",
    "5. Уникальных таймстампов немного меньше, чем id событий (даже с учетом пропусков)\n",
    "#### purchase_df\n",
    "1. Пропусков нет\n",
    "2. id покупок столько же, сколько пользователей\n",
    "#### Сумма покупки\n",
    "1. Поле **purchase_df['**amount**']** выглядит как обычная сумма покупки, аномалий не прослеживается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Фильтрация и соединение исходных данных\n",
    "# 3.1. Формируем выборку пользователей по условию задания\n",
    "filtering_sample = ( events_df\n",
    "    .query (f\"event_type=='registration' & start_time.dt.year==2018\")\n",
    "    ['user_id'].unique ()\n",
    ")\n",
    "\n",
    "# 3.2 Фильтруем и слегка подобрабатываем датафреймы\n",
    "events_df_filtered = ( events_df\n",
    "    .query (f\"user_id in @filtering_sample\")\n",
    "    .rename (columns={'id': 'event_id'})\n",
    ")\n",
    "\n",
    "purchase_df_filtered = ( purchase_df\n",
    "    .query (f\"user_id in @filtering_sample\")\n",
    "    .rename (columns={'id': 'purchase_id', 'event_datetime': 'start_time'})\n",
    "    .assign (**{'event_type': 'purchase'})\n",
    ")\n",
    "\n",
    "# 3.3 Соединяем. Вот с этим мы будем работать\n",
    "events_combined = \\\n",
    "(   pd.concat( [events_df_filtered, purchase_df_filtered], sort=False )\n",
    "    .reset_index (drop=True)\n",
    "    .sort_values (by='start_time')\n",
    "    .astype\n",
    "    ({  'selected_level':   pd.api.types.CategoricalDtype(categories=levels_arranged, ordered=True)\n",
    "        , 'event_type':     pd.api.types.CategoricalDtype(categories=events_arranged, ordered=True)\n",
    "    })\n",
    ")\n",
    "\n",
    "# Получился датафрейм следующего формата:\n",
    "print ('events_combined')\n",
    "display (df_describe (events_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исследуем структуру данных по событиям\n",
    "# 1. Посчитаем количество событий каждого вида в жизни пользователя\n",
    "event_times_per_user = \\\n",
    "(events_combined.pivot_table\n",
    "    (   index = 'user_id'\n",
    "        , columns = 'event_type'\n",
    "        , values = 'start_time'\n",
    "        , aggfunc = 'count'\n",
    "    )\n",
    ")\n",
    "# 2. Теперь рассмотрим результаты\n",
    "event_times_per_user.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Распределение событий в жизни пользователя\n",
    "1. Регистрация происходит ровно 1 раз (не зарегистрировавшиеся пользователи в статистику просто не попали)\n",
    "2. level_choice, pack_choice, purchase происходят 0 или 1 раз, т.е. либо могут не происходить, но если происходят, то 1 раз *(что странно)*\n",
    "3. Среднее по ним при этом убывает, т.к. каждое следующее событие совершает меньшее кол-во пользователей\n",
    "4. У tutorial_start, tutorial_finish максимум 9 (т.е. кто-то максимум 9 раз начинал и заканчивал обучение), \n",
    "5. Но средние различаются, доля закончивших обучение меньше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравним статистику по началам и завершениям обучений.\n",
    "start_column = event_times_per_user['tutorial_start'].value_counts()\n",
    "finish_column = event_times_per_user['tutorial_finish'].value_counts()\n",
    "\n",
    "tutorials_per_user = pd.DataFrame \\\n",
    "    ({  'start': start_column\n",
    "        , 'finish': finish_column\n",
    "        , 'start, %': (start_column / start_column.sum()).round(3)*100\n",
    "        , 'finish, %': (finish_column / finish_column.sum()).round(3)*100\n",
    "    })\n",
    "tutorials_per_user.index.rename('times', inplace=True)\n",
    "display (tutorials_per_user)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Начала и зввершения обучений\n",
    "* 40% пользователей не начинали обучение, 46% начинали 1 раз, 8% начинали 2 раза. \n",
    "* Далее (до 9 раз) идут не очень существенные в процентном отношении, но заметные в абсолютном количества (десятки и сотни людей)\n",
    "* 49% пользователей не закончили обучение. 40% закончили 1 раз, 7% закончили 2 раза\n",
    "* Далее - картина аналогична начавшим обучение (но в среднем чуть меньше для каждого кол-ва раз)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка к заполнению основной таблицы\n",
    "max_event_per_user = \\\n",
    "(events_combined\n",
    "    .groupby (['user_id'],as_index=False)\n",
    "    ['event_type'].max()\n",
    "    .rename (columns={'event_type':'last_event'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем основную таблищу, с которой будем раборать\n",
    "\n",
    "users_event_data = \\\n",
    "(events_combined\n",
    "    .groupby (['user_id', 'event_type'])\n",
    "    ['start_time']\n",
    "    .agg(['count','min','max'])\n",
    "    .rename (columns={'min': 'first', 'max': 'last'})\n",
    "    .assign\n",
    "    (**{  'first_dif': lambda df: df.groupby(['user_id'])['first'].diff()\n",
    "        , 'last_dif': lambda df: df.groupby(['user_id'])['last'].diff()\n",
    "    })\n",
    "    .reset_index()\n",
    "    .merge (max_event_per_user, left_on='user_id',right_on='user_id')\n",
    "    .set_index(['user_id', 'event_type'])\n",
    ")\n",
    "users_event_data.head (50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пробуем отвечать на вопрос №1\n",
    "# Отличается ли время прохождения различных этапов у пользователей, которые прошли обучение, и пользователей, не начинавших обучение\n",
    "(users_event_data\n",
    "    .query \n",
    "    (f\"last_event>'tutorial_finish'\"\n",
    "     f\"and event_type == 'tutorial_start'\"\n",
    "    )\n",
    "    ['count'].value_counts()\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_event_data_wide = \\\n",
    "(events_combined\n",
    "    .groupby (['user_id', 'event_type'])\n",
    "    ['start_time']\n",
    "    .agg(['count','min'])\n",
    "    .rename (columns={'min': 'first'})\n",
    "    .assign\n",
    "    (**{  'first_dif': lambda df: df.groupby(['user_id'])['first'].diff()\n",
    "    })\n",
    "    .reset_index()\n",
    "    .merge (max_event_per_user, left_on='user_id',right_on='user_id')\n",
    "    .pivot_table\n",
    "    (   index=['user_id', 'last_event']\n",
    "        , columns='event_type'\n",
    "        , values=['count', 'first', 'first_dif']\n",
    "        , aggfunc= lambda x: x\n",
    "    )\n",
    "    .apply (flatten_headers)\n",
    ")\n",
    "users_event_data_wide.head (20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изучаем сплющивание имен столбцов\n",
    "# 0. Смотрим, что есть. Есть MultiIndex, состоящий из кортежей\n",
    "users_event_data_wide.columns\n",
    "# MultiIndex([(    'count',    'registration'),\n",
    "#             (    'count',  'tutorial_start'),\n",
    "#             ...\n",
    "# 1. Плющим - этап 1. Получаем \"плоский\" индекс. Его элементы - все те же кортежи, но он уже плоский, не разбиваемый на уровни\n",
    "users_event_data_wide.columns.to_flat_index()\n",
    "# Index([       ('count', 'registration'),      ('count', 'tutorial_start'), ...\n",
    "# 2. Плющим - этап 2 - из этих кортежей получаем моностроковые имена. В виде списка.\n",
    "[':'.join([x for x in col]) \n",
    " for col in users_event_data_wide.columns.to_flat_index()\n",
    "]\n",
    "# 3. А теперь внимание - пробуем наложить этот наш список на исходный индекс столбцов\n",
    "users_event_data_wide.columns = \\\n",
    "[':'.join([x for x in col]) \n",
    " for col in users_event_data_wide.columns.to_flat_index()\n",
    "]\n",
    "users_event_data_wide\n",
    "# Сработало!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(users_event_data_wide\n",
    "    .apply (lambda df:\n",
    "        df.rename\n",
    "        ([':'.join([x for x in col]) for col in df.columns.to_flat_index()], axis='columns'\n",
    "         )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Как работает query с многоуровневыми столбцами:\n",
    "\n",
    "(users_event_data_wide\n",
    "    .query (\"`('count', 'tutorial_start')`>1\")\n",
    ")\n",
    "\n",
    "\n",
    "# [['user_id', 'last_event']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
